{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/teamspace/studios/this_studio/dataset/supervised/dataset/train'\n",
    "test_dir = '/teamspace/studios/this_studio/dataset/supervised/dataset/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "def extract_zip(zip_path, extract_to):\n",
    "    \"\"\"\n",
    "    Extracts the ZIP file to the specified folder.\n",
    "    \n",
    "    Args:\n",
    "        zip_path (str): Path to the ZIP file.\n",
    "        extract_to (str): Folder where the ZIP file will be extracted.\n",
    "    \"\"\"\n",
    "    # Check if the ZIP file exists\n",
    "    if not os.path.exists(zip_path):\n",
    "        raise FileNotFoundError(f\"{zip_path} not found.\")\n",
    "    \n",
    "    # Check if the extraction target folder exists, create it if not\n",
    "    if not os.path.exists(extract_to):\n",
    "        os.makedirs(extract_to)\n",
    "    \n",
    "    # Open the ZIP file and extract its contents\n",
    "    shutil.unpack_archive(zip_path, extract_to)\n",
    "    print(f\"ZIP file extracted to {extract_to} folder.\")\n",
    "\n",
    "# Example usage\n",
    "zip_file_path = '/teamspace/studios/this_studio/archive.zip'\n",
    "extract_folder = '/teamspace/studios/this_studio/dataset'\n",
    "extract_zip(zip_file_path, extract_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import efficientnet_b0\n",
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define transformations\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomRotation(degrees=(-45, 45)),  # Random rotation within -45 to 45 degrees\n",
    "    transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.1),  # Random color changes\n",
    "    transforms.Resize((224, 224)),  # Resize to 224x224 pixels\n",
    "    transforms.ToTensor(),  # Convert the image to a tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the tensor\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to 224x224 pixels\n",
    "    transforms.ToTensor(),  # Convert the image to a tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the tensor\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = ImageFolder(root=train_dir, transform=transform_train)\n",
    "val_dataset = ImageFolder(root=test_dir, transform=transform_val)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Load a pre-trained EfficientNet-B0 model\n",
    "model = efficientnet_b0(weights='IMAGENET1K_V1')\n",
    "\n",
    "# Replace the final fully connected layer\n",
    "num_features = model.classifier[1].in_features\n",
    "num_classes = len(train_dataset.classes)  # Automatically determine number of classes\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.2),\n",
    "    nn.Linear(num_features, num_classes)\n",
    ")\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Define the learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 15\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in tqdm(train_loader):\n",
    "        # Move data to GPU if available\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    scheduler.step()  # Update learning rate\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader)}, train_acc: {100 * correct / total}%\")\n",
    "    \n",
    "    if (epoch % 3 == 0):\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for images, labels in tqdm(val_loader):\n",
    "                # Move data to GPU if available\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "            print(f'Validation Accuracy: {100 * correct / total}%')\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'efficientnet_b0_custom_1.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch [1/10], Loss: 0.7787453474622246, train_acc: 77.18888888888888%\n",
    "Validation Accuracy: 91.2%\n",
    "Epoch [2/10], Loss: 0.33777626856157544, train_acc: 89.88888888888889%\n",
    "Epoch [3/10], Loss: 0.26598419727929307, train_acc: 91.47777777777777%\n",
    "Epoch [4/10], Loss: 0.22585981896688753, train_acc: 92.82222222222222%\n",
    "Validation Accuracy: 93.7%\n",
    "Epoch [5/10], Loss: 0.2021464193239808, train_acc: 93.86666666666666%\n",
    "Epoch [6/10], Loss: 0.09893491388965689, train_acc: 96.8%\n",
    "Epoch [7/10], Loss: 0.06436489645188595, train_acc: 97.96666666666667%\n",
    "Validation Accuracy: 96.7%\n",
    "Epoch [8/10], Loss: 0.054149052723482624, train_acc: 98.23333333333333%\n",
    "Epoch [9/10], Loss: 0.04353517838687709, train_acc: 98.78888888888889%\n",
    "Epoch [10/10], Loss: 0.0374356541990679, train_acc: 98.86666666666666%\n",
    "Validation Accuracy: 96.8%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import efficientnet_b0\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation loop\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "model.eval()\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in tqdm(val_loader):\n",
    "        # Move data to GPU if available\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    print(f'Validation Accuracy: {100 * correct / total}%')\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    precision = precision_score(all_labels, all_predictions, average='weighted')\n",
    "    recall = recall_score(all_labels, all_predictions, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "    cm = confusion_matrix(all_labels, all_predictions)\n",
    "    \n",
    "    print(f'Validation Metrics: Accuracy: {accuracy*100}%, Precision: {precision*100}%, Recall: {recall*100}%, F1 Score: {f1*100}%')\n",
    "    \n",
    "# Plot the confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=train_dataset.classes, yticklabels=train_dataset.classes)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation Accuracy: 96.8%\n",
    "Validation Metrics: Accuracy: 96.8%, Precision: 96.87781133598462%, Recall: 96.8%, F1 Score: 96.79142002572321%\n",
    "\n",
    "##You can see confusion matrix in output.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "image_path = '/teamspace/studios/this_studio/yalikavak-marina-6-350x250.jpg'\n",
    "image = Image.open(image_path)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize to 224x224 pixels\n",
    "    transforms.ToTensor(),  # Convert the image to a tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the tensor\n",
    "])\n",
    "\n",
    "# Apply the transformations\n",
    "image = transform(image).unsqueeze(0)  # Add a batch dimension\n",
    "\n",
    "# Move the image to the same device as the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "image = image.to(device)\n",
    "\n",
    "# Forward pass\n",
    "with torch.no_grad():\n",
    "    outputs = model(image)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "# Interpret the output\n",
    "class_names = train_dataset.classes  # Assuming you have a list of class names\n",
    "predicted_class = class_names[predicted.item()]\n",
    "print(f'Predicted class: {predicted_class}')\n",
    "print(f'Actual class: Port') ## port image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicted class: Port\n",
    "Actual class: Port"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
